import subprocess
import sys
import time

def run_command(command, description):
    """Run a command and show output"""
    print(f"ğŸ”„ {description}...")
    print(f"ğŸ“ Command: {command}")
    
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"âœ… {description} completed successfully!")
            if result.stdout:
                print(f"ğŸ“„ Output: {result.stdout.strip()}")
            return True
        else:
            print(f"âŒ {description} failed!")
            if result.stderr:
                print(f"ğŸ“„ Error: {result.stderr.strip()}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"â±ï¸ {description} timed out after 5 minutes")
        return False
    except Exception as e:
        print(f"âŒ {description} error: {e}")
        return False

def main():
    print("ğŸš€ Setting up MythoMax L2 13B Model...")
    print("=" * 50)
    
    # Step 1: Check if Ollama is running
    print("ğŸ” Step 1: Checking Ollama status...")
    if not run_command("ollama list", "Checking available models"):
        print("âŒ Ollama might not be running. Please start Ollama first:")
        print("   ollama serve")
        return False
    
    # Step 2: Pull the MythoMax model
    print("\nğŸ“¦ Step 2: Downloading MythoMax model...")
    print("âš ï¸ This will download ~8GB and may take 10-30 minutes depending on your internet speed")
    
    if not run_command("ollama pull mythomax-l2-13b", "Downloading MythoMax L2 13B"):
        print("âŒ Failed to download MythoMax model")
        return False
    
    # Step 3: Verify the model is available
    print("\nâœ… Step 3: Verifying model installation...")
    if run_command("ollama list", "Listing models"):
        print("\nğŸ‰ MythoMax L2 13B setup completed successfully!")
        print("ğŸ“‹ You can now use the model with:")
        print("   ollama run mythomax-l2-13b")
        print("   or in your AI app with model name: 'mythomax-l2-13b'")
        return True
    else:
        print("âŒ Model verification failed")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ¯ Next steps:")
        print("1. Update your AI app to use 'mythomax-l2-13b' as the model")
        print("2. Run: python local_gguf_ai_app.py")
        print("3. Test with: 'who created you?' and other questions")
    else:
        print("\nğŸ’¡ Troubleshooting:")
        print("1. Make sure Ollama is running: ollama serve")
        print("2. Check your internet connection")
        print("3. Try again: python setup_mythomax.py")
    
    input("\nPress Enter to continue...") 