#!/usr/bin/env python3
"""
SUNDAY-PAAI Starter Script
"""

import subprocess
import sys
import time

def check_ollama():
    """Check if Ollama is running"""
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            print(f"âœ… Ollama is running - Found {len(models)} models")
            for model in models:
                print(f"   ğŸ“¦ {model['name']}")
            return True
        else:
            print("âŒ Ollama not responding")
            return False
    except Exception as e:
        print(f"âŒ Ollama not running: {e}")
        print("ğŸ’¡ Start Ollama with: ollama serve")
        return False

def start_flask_app():
    """Start the Flask app"""
    print("\nğŸš€ Starting SUNDAY-PAAI Flask Server...")
    
    try:
        # Import and run the improved app
        from improved_app import app
        
        print("âœ… Flask app imported successfully!")
        print("ğŸŒ Server will be available at: http://localhost:8080")
        print("ğŸ“‹ Press Ctrl+C to stop the server")
        
        app.run(debug=True, host='127.0.0.1', port=8080)
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("ğŸ’¡ Make sure improved_app.py exists")
    except Exception as e:
        print(f"âŒ Error starting server: {e}")
        print("ğŸ’¡ Trying alternative port...")
        try:
            app.run(debug=True, host='127.0.0.1', port=5000)
        except Exception as e2:
            print(f"âŒ Error with port 5000: {e2}")

def main():
    print("ğŸ¤– SUNDAY-PAAI AI Assistant Starter")
    print("=" * 40)
    
    # Check Ollama first
    if not check_ollama():
        print("\nâš ï¸  Please start Ollama first:")
        print("   ollama serve")
        return
    
    # Start Flask app
    start_flask_app()

if __name__ == "__main__":
    main() 